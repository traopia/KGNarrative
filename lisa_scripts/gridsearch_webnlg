#!/bin/bash
#SBATCH --job-name=gridsearch
#SBATCH --time=20:00:00
#SBATCH -N 1
## #SBATCH --ntasks-per-node=1
#SBATCH --partition=gpu_titanrtx_shared
#SBATCH --gpus-per-task=4
#SBATCH --output=gridsearch.out
## in the list above, the partition name depends on where you are running your job. 
## On DAS5 the default would be `defq` on Lisa the default would be `gpu` or `gpu_shared`
## Typing `sinfo` on the server command line gives a column called PARTITION.  There, one can find the name of a specific node, the state (down, alloc, idle etc), the availability and how long is the ti$


# Load GPU drivers
## For Lisa modules are usually not needed, so remove the previous 2 lines. https://userinfo.surfsara.nl/systems/shared/modules 



# This loads the anaconda virtual environment with our packages
###export CUDA_VISIBLE_DEVICES=0,1,2,3

source /home/ghoogerw/.bashrc

conda activate kg2Narrative

# Base directory for the experiment. This should be your outer folder, actually where this script is 
cd /home/ghoogerw/kg2Narrative/

echo FINETUNIING_NOW_INSTANCES
python3 KGNarrative2/script4trainingLLM/gridsearch.py KGNarrative2/Datasets/WebNLG/4experiment full Instances_KG bart-large webnlg_gridsearch/Instances 
echo NOW_TRYING_TYPES-------------------
python3 KGNarrative2/script4trainingLLM/gridsearch.py KGNarrative2/Datasets/WebNLG/4experiment full Types_KG bart-large webnlg_gridsearch/Types
echo NOW_TRYING_REIFICATION------------------
python3 KGNarrative2/script4trainingLLM/gridsearch.py KGNarrative2/Datasets/WebNLG/4experiment full semantic_of_news bart-large webnlg_gridsearch/reification



