#!/bin/bash
#SBATCH --job-name=webnlg_reification
#SBATCH --time=20:00:00
#SBATCH -N 1
## #SBATCH --ntasks-per-node=1
#SBATCH --partition=gpu_titanrtx_shared
#SBATCH --gpus-per-task=4
#SBATCH --output=webnlgSemantic.out
## in the list above, the partition name depends on where you are running your job. 
## On DAS5 the default would be `defq` on Lisa the default would be `gpu` or `gpu_shared`
## Typing `sinfo` on the server command line gives a column called PARTITION.  There, one can find the name of a specific node, the state (down, alloc, idle etc), the availability and how long is the ti$


# Load GPU drivers
## For Lisa modules are usually not needed, so remove the previous 2 lines. https://userinfo.surfsara.nl/systems/shared/modules 



# This loads the anaconda virtual environment with our packages
###export CUDA_VISIBLE_DEVICES=0,1,2,3

source /home/ghoogerw/.bashrc

conda activate kg2Narrative

# Base directory for the experiment. This should be your outer folder, actually where this script is 
cd /home/ghoogerw/kg2Narrative/


cols=('Instances_KG'  'Types_KG' 'Subclasses_KG' 'Instances_list')
for element in "${cols[@]}"
do
    echo FINETUNIING_NOW_ON_$element
    python3  KGNarrative2/script4trainingLLM/finetunemodel.py KGNarrative2/Datasets/WebNLG/4experiment pop $element bart-base webnlg_scripts/Semantic_results/$element
    echo DONE
done
#python3 KGNarrative2/script4trainingLLM/2ndfinetune_BART.py KGNarrative2/Datasets/DWIE/DWIE_semantics DWIE 'Instances Knowledge Graph' megaBART/finetuned_BART_EventNarrative DWIE_InstanceKG



# run the script

