[
    {
        "test_loss": 0.1487768143415451,
        "test_rouge1": 0.6711575204518265,
        "test_rouge2": 0.41440150201812886,
        "test_rougeL": 0.4634517848042349,
        "test_rougeLsum": 0.4634047472417471,
        "test_runtime": 132.3187,
        "test_samples_per_second": 2.524,
        "test_steps_per_second": 0.635
    },
    {
        "bleu": 0.3053248354784931,
        "precisions": [
            0.6261726395356685,
            0.3689152799834288,
            0.2357057035832921,
            0.15960912052117263
        ],
        "brevity_penalty": 1.0,
        "length_ratio": 1.081453908473834,
        "translation_length": 14817,
        "reference_length": 13701
    },
    {
        "google_bleu": 0.32542936466942146
    },
    {
        "meteor": 0.5137228585844371
    },
    {
        "Bert_Score": {
            "precision": 0.8834127032471274,
            "recall": 0.9016097655553303,
            "f1": 0.8918962972963641
        }
    },
    {
        "bleurt_score": 0.6853653792581872
    },
    {
        "PARENT": {
            "precision": 0.39996760289392697,
            "recall": 0.4544131523753813,
            "f_score": 0.39818120549154795
        }
    },
    {
        "time(s)": 703.2804975509644
    },
    {
        "gpu": 14116
    }
][
    {
        "typeKG": "Subclasses_KG"
    },
    {
        "hyper_Params": [
            0.0001,
            1,
            3
        ]
    },
    {
        "test_loss": 0.3861067593097687,
        "test_rouge1": 0.21571701454831477,
        "test_rouge2": 0.035159818898479134,
        "test_rougeL": 0.14473904318192315,
        "test_rougeLsum": 0.14464649767568408,
        "test_runtime": 108.9969,
        "test_samples_per_second": 3.064,
        "test_steps_per_second": 0.771
    },
    {
        "bleu": 0.02769242457577596,
        "precisions": [
            0.2089321357285429,
            0.03207145031969958,
            0.012285773281024159,
            0.007143607521798509
        ],
        "brevity_penalty": 1.0,
        "length_ratio": 1.4626669586161594,
        "translation_length": 20040,
        "reference_length": 13701
    },
    {
        "google_bleu": 0.0654359879032258
    },
    {
        "meteor": 0.1534134990981275
    },
    {
        "Bert_Score": {
            "precision": 0.6475993161072988,
            "recall": 0.6727694960054523,
            "f1": 0.6597284867378053
        }
    },
    {
        "bleurt_score": 0.33298469535604924
    },
    {
        "time(s)": 718.0706868171692
    },
    {
        "gpu": 11524
    }
]