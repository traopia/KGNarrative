[
    {
        "test_loss": 0.16757622361183167,
        "test_rouge1": 0.6272471133753035,
        "test_rouge2": 0.3764462711721872,
        "test_rougeL": 0.4277818394961318,
        "test_rougeLsum": 0.42791169480467584,
        "test_runtime": 112.1169,
        "test_samples_per_second": 2.979,
        "test_steps_per_second": 0.749
    },
    {
        "bleu": 0.27920627439475765,
        "precisions": [
            0.5984596169858452,
            0.34202301463276036,
            0.21245634458672877,
            0.13974645786726322
        ],
        "brevity_penalty": 1.0,
        "length_ratio": 1.0518940223341362,
        "translation_length": 14412,
        "reference_length": 13701
    },
    {
        "google_bleu": 0.2961218656619462
    },
    {
        "meteor": 0.4701791397294948
    },
    {
        "Bert_Score": {
            "precision": 0.8670852901692876,
            "recall": 0.8827956215350213,
            "f1": 0.8743387905066599
        }
    },
    {
        "bleurt_score": 0.6410756021916509
    },
    {
        "PARENT": {
            "precision": 0.38257015025541713,
            "recall": 0.4256116914391754,
            "f_score": 0.372701321041475
        }
    },
    {
        "time(s)": 714.4959940910339
    },
    {
        "gpu": 11524
    }
][
    {
        "typeKG": "Instances_list"
    },
    {
        "hyper_Params": [
            0.0001,
            1,
            3
        ]
    },
    {
        "test_loss": 0.15904368460178375,
        "test_rouge1": 0.6197417230679111,
        "test_rouge2": 0.3702973264427888,
        "test_rougeL": 0.43115614713737216,
        "test_rougeLsum": 0.4312470502519254,
        "test_runtime": 117.1284,
        "test_samples_per_second": 2.852,
        "test_steps_per_second": 0.717
    },
    {
        "bleu": 0.2715176503225039,
        "precisions": [
            0.584822934232715,
            0.3268925539990339,
            0.2066115702479339,
            0.13759675902481372
        ],
        "brevity_penalty": 1.0,
        "length_ratio": 1.0820378074593096,
        "translation_length": 14825,
        "reference_length": 13701
    },
    {
        "google_bleu": 0.29432463842975204
    },
    {
        "meteor": 0.4677790220688014
    },
    {
        "Bert_Score": {
            "precision": 0.8602511829244877,
            "recall": 0.8854946676128639,
            "f1": 0.8722227626218053
        }
    },
    {
        "bleurt_score": 0.6341797084865456
    },
    {
        "time(s)": 721.3706569671631
    },
    {
        "gpu": 11524
    }
]