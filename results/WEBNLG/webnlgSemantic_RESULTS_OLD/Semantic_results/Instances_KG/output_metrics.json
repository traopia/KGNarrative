[
    {
        "test_loss": 0.15886469185352325,
        "test_rouge1": 0.6693262714935926,
        "test_rouge2": 0.41420345654053303,
        "test_rougeL": 0.4619482986135891,
        "test_rougeLsum": 0.4619745004438581,
        "test_runtime": 108.6134,
        "test_samples_per_second": 3.075,
        "test_steps_per_second": 0.773
    },
    {
        "bleu": 0.30903906344239773,
        "precisions": [
            0.6352598348712968,
            0.3768733574827758,
            0.23797744634412513,
            0.1600924614122735
        ],
        "brevity_penalty": 1.0,
        "length_ratio": 1.0519670097073206,
        "translation_length": 14413,
        "reference_length": 13701
    },
    {
        "google_bleu": 0.3250703119890117
    },
    {
        "meteor": 0.5098910446451791
    },
    {
        "Bert_Score": {
            "precision": 0.8859181871671162,
            "recall": 0.8980246650244661,
            "f1": 0.891499945325052
        }
    },
    {
        "bleurt_score": 0.6881157721944912
    },
    {
        "PARENT": {
            "precision": 0.4035547191588561,
            "recall": 0.45407924747403033,
            "f_score": 0.40106254887361886
        }
    },
    {
        "time(s)": 713.4186265468597
    },
    {
        "gpu": 11524
    }
][
    {
        "typeKG": "Instances_KG"
    },
    {
        "hyper_Params": [
            0.0001,
            1,
            3
        ]
    },
    {
        "test_loss": 0.13573530316352844,
        "test_rouge1": 0.6725667471936183,
        "test_rouge2": 0.41320130738954386,
        "test_rougeL": 0.465307613211972,
        "test_rougeLsum": 0.46509384801176035,
        "test_runtime": 117.6721,
        "test_samples_per_second": 2.838,
        "test_steps_per_second": 0.714
    },
    {
        "bleu": 0.301782942361746,
        "precisions": [
            0.6268291022936092,
            0.36311720871927017,
            0.23215686274509803,
            0.1569644291870572
        ],
        "brevity_penalty": 1.0,
        "length_ratio": 1.0724034741989636,
        "translation_length": 14693,
        "reference_length": 13701
    },
    {
        "google_bleu": 0.3241939703093323
    },
    {
        "meteor": 0.5117866542038285
    },
    {
        "Bert_Score": {
            "precision": 0.8828648459054753,
            "recall": 0.9032162649188927,
            "f1": 0.8925605612600634
        }
    },
    {
        "bleurt_score": 0.6906769682547289
    },
    {
        "time(s)": 720.4039914608002
    },
    {
        "gpu": 11512
    }
]